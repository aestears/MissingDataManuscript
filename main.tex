 \documentclass{article}
\usepackage[utf8]{inputenc}




\usepackage{geometry}                		
\geometry {letterpaper, left=2.5 cm, right=2.5 cm, top=2.5cm, bottom=2.5 cm}    


\usepackage{multirow}
\usepackage{graphicx}		
\graphicspath{ {c:} }
\usepackage{setspace}
\usepackage[version=4]{mhchem}
\doublespace
\usepackage{siunitx}
\usepackage{natbib}
\usepackage{amsmath}
\usepackage{bm}
\usepackage{amsfonts}
\usepackage{lineno}
\usepackage{gensymb}
\usepackage[sharp]{easylist}%makes nice outlines.  Use # for symbol
\usepackage{blkarray}
\usepackage{lastpage}

\begin{document}

%\maketitle

{\Large \noindent \bf %Approaches for handling missing data in ecological time series
Accounting for missing data in autoregressive models of ecological time series
}

\medskip

\noindent Alice Stears\textsuperscript{*}, 
Melissa DeSiervo\textsuperscript{*},
Dusty Gannon,
Amy Patterson,
Alice Carter,
Joanna Blaszczak,
Matt Trentman,
Eliza Grames,
Robert O. Hall, Jr,
Josh Jahner,
Saheed O. Jimoh,
Heili Lowman, % ask Heili again
Courtenay A. Ray,
Christa Torrens,
Lauren Shoemaker$^{\circ}$,
Christopher Weiss-Lehman$^{\circ}$


\noindent Target Journal: Ecology, as a ``Statistical Innovations" article (https://esajournals.onlinelibrary.wiley.com/hub/journal/19399170/author-guidelines) 

\noindent Page count: \pageref{LastPage}/30

\clearpage

%\begin{linenumbers}

\section*{Abstract (199/200 words)} % From Amy's ESA abstract
Long time series are valuable and increasingly available tools for understanding ecological systems. Unfortunately, missing data can impede their utility. While several methods exist, there is no established best practice for handling missing data in autoregressive time series models. Using simulated and empirical time series of primary productivity in a river and great tit population size, we explored the performance of six missing data approaches across scenarios with varying amounts and types of missing data. In each scenario, we assessed how statistical models fit using each missing data approach recovered model parameters used to simulate data and forecast held out time steps. When data were missing completely at random, parameters were recovered well even with as high as 50\% missingness. Conversely, parameter estimates and forecasts were unreliable when data were missing not at random. The best performing missing data approaches were the Kalman filter and data augmentation for time series with Gaussian error (primary productivity example), and data augmentation and complete case data deletion for time series with Poisson error (population size example). Our study emphasizes that one should avoid simple data deletion, especially for population count data, and use extreme caution when data are missing not at random.

\section*{Keywords}
Time series; missing data; autoregressive models; forecasting; simulations

\section*{Introduction} 

Long-term time series contribute to our understanding of many ecological phenomena, from the impacts of species diversity on predator-prey dynamics to patterns of nutrient cycling in ecosystems \citep{Hughes2017, Likens1970, Sinclair2003}. There has been a concerted effort in recent years to facilitate the collection of long-term ecological datasets (e.g. the U.S National Science Foundation Long Term Ecological Research Program (NSF LTER), and the Smithsonian Forest Global Earth Observatory (ForestGEO)), as well as to re-analyze historical long-term datasets with modern methods \citep{Adler2009, Buma2017}. Long time series of ecological data are likely to have missing observations, due in part to unpredictable environmental barriers to complete data collection that are difficult if not impossible to overcome \citep{lopucki2022handling, nakagawa_missing_2008}. Challenges include faulty sensors \citep{hossie_confronting_2021}, inaccessibility of field sites due to weather, and human error during data entry or collection. Due to the temporal nature of time series data, it is impossible to retroactively collect data to fill in missing observations. These missing data have cascading negative effects on subsequent analysis including reduced statistical power \citep{kang2013prevention, moritz_imputets_2017} and possibly biased estimation of parameters, leading to both inaccurate and imprecise conclusions \citep{aleryani2018dealing, kim_transcending_2018, junger_imputation_2015}


The prevalence of missing data in ecological time series data is itself problematic, but can be compounded by the characteristics of ecological time series and the statistical approaches used to model them. First, ecological time series are often autoregressive, meaning that the value of a data point depends in part on the values of previous observations %(e.g., population counts through time or nutrient fluxes within a system) 
Thus, a single missing observation could lead to the effective deletion of multiple data points. Further, many ecological time series consist of discrete data such as Poisson-distributed counts or binomial presence-absence data, which precludes the use of classical ARIMA models. Approaches that directly impute missing values or are model-based must be adjusted to account for time series that do not conform to classical models that assume Gaussian error distributions.

An additional challenge is accounting for the mechanisms driving missingness in a time series, i.e. the statistical relationship between observations and the probability that a given observation goes missing. Missing data can be Missing Completely at Random (MCAR), Missing Not at Random (MNAR), or Missing at Random (MAR) \citep[][Fig. \ref{fig:missingtypes}]{rubin_inference_1976, nakagawa_missing_2015}. Data are MCAR when the probability of a missing observation is independent of both the numerical value of the observation itself, as well as any external information available (e.g. the value of a covariate) \citep{nakagawa_missing_2015, horton2007much, newman_missing_2014}. %When data are MCAR, the pattern of missingness in the response variable can vary along a spectrum from low autocorrelation (whether a previous time step's data point is missing does not impact whether the current data point is missing) to high autocorrelation (if the previous data point is missing, the current data point is more likely to be missing). 
Data are MNAR when the probability of missingness depends on the value of either the missing observation (e.g. a temperature sensor cannot record values above a threshold, so observations above that value are missing) or an unmeasured predictor (e.g.  high stream flow may lead to missing observations in both the stream gauge and turbidity sensors, so the missing turbidity values are dependent on the missing stream gauge values). Data are MAR when the probability of missingness is not related to the numerical value of the missing observation, but the probability that an observation goes missing can be explained by one or more observed predictor variables (e.g. a population age-weight dataset is  missing weights for young-of-the-year because that age class is considered  too delicate to handle ) \citep{newman_missing_2014, ellington_using_2015, nakagawa_missing_2015}. The key difference between MAR and MNAR data is whether the variables that affect missingness are observed and can therefore be conditioned on (MAR) or unobserved (MNAR) \citep{nakagawa_model_2011}. That is, given the known variables driving missingness in MAR data, it can be handled like MCAR data \citep{nakagawa_missing_2015}. Thus, MCAR and MNAR represent the two extremes of missing data in terms of the statistical complications they pose. 
%Our analyses focus on MAR and MNAR only because they are prevalent in ecological time series, and are concerned only with missing values in the response variable, which makes it easier to compare methods across time series with different error structures. Whether data are MAR or MNAR can have a high impact on the accuracy and precision of statistical models and the approaches used to account for missing data \citep{newman_missing_2014, dong2013principled}. 


Fortunately, multiple families of methods exist for dealing with missing data in general (Fig. \ref{fig:ConceptualFigure}). Broadly speaking, these methods can be categorized into simple data processing approaches that occur prior to full statistical analysis or more complex model-based approaches that directly incorporate a model for missingness into the model-fitting process. The former category primarily consists of what we call "data deletion approaches" (Fig. \ref{fig:ConceptualFigure} A) and imputation, either with a point estimate for the missing observations (single imputation, SI) or with multiple imputed values (multiple imputation, MI) (Fig. \ref{fig:ConceptualFigure} B)\citep{nakagawa_model_2011, nakagawa_missing_2015, kang2013prevention, onkelinx_working_2017, rubin1996multiple, rubin1988overview}. In contrast, model-based approaches are generally designed to maximize the likelihood of the observed data while explicitly acknowledging missing values or sample from a joint posterior distribution that considers the missing values as parameters to be estimated. These include expectation maximization (EM) \citep{nadjafi2022expectation,li2019expectation, kang2013prevention}, the Kalman filter \citep{kalman_filter_1960}, 
and data augmentation (DA) \citep{kong_sequential_1994}.  

 These approaches for dealing with missing data have been applied to ecological data \citep{Newman2023, Soldaat2007}, but their relative performance is unclear, particularly when confronted with time series that have different amounts and types of missing data. Additionally, while the Kalman filter method was developed specifically for autoregressive time series data, it is unclear how other approaches perform when applied to autoregressive time series. Finally, not all approaches can be adapted to function with bounded or discrete data that do not conform to the standard assumptions of Gaussian-distributed error, and when they can be, it is unclear how adapting them for non-Gaussian error distributions may impact their performance.

Here, we evaluate the precision and accuracy of different statistical approaches for dealing with missing data in autoregressive models of ecological time series. We test these approaches on real and simulated datasets with both Gaussian and Poisson error distributions. We artificially introduce missingness of different types and increasing amounts into these time series, and then quantify the performance of different missing data approaches across in terms of accuracy and precision of both the point estimates and their respective interval estimates for model parameters of interest. This provides a needed comparison of multiple previously proposed approaches for dealing with missing data in time series, which will be a resource for ecologists and environmental scientists in search of robust, reproducible methods for confronting time series models with missing data.

\section*{Methods} 

\subsection*{Overview}


Broadly, we compared the performance of six approaches for dealing with missing data in time series when applied to two types of both real and simulated time series with different amounts and types of artificially induced missingness. We first discuss the two methods we used to simulate time series with either Gaussian-distributed or Poisson-distributed error, then describe the two empirical datasets we used. %*While we recognize that our Gaussian GPP values are modeled using empirical data, for brevity we hereafter refer to both real-world datasets as 'empirical'. 
We also describe the methods we used to remove observations, which generated time series with different amounts and types of missingness. Finally, we present the six  "missing data approaches" we used, and describe how we quantified their performance in terms of the precision and accuracy in estimate parameters of interest in the presence of different amounts and types of missing data.   

\subsection*{Simulated and empirical Gaussian autoregressive time series models}

The use of sensors that collect daily or hourly readings of environmental data has become ubiquitous in environmental research. Despite their prevalence, these types of data are prone to missingness \citep{chen2013ecological}. For these reasons, we evaluated the impact of missingness using both simulated and empirical data that represent daily measures of environmental and response variables from a sensor. These data with Gaussian distributed error, thus are subsequently referred to as “real-valued time series”.  

We simulated Gaussian time series using a first-order auto-regressive (AR(1)) error model with explanatory covariates, such that:

\begin{equation}
    Y_t = {\bf x}_t'{\bm \beta} + \phi (Y_{t-1} - {\bf x}_{t-1}'{\bm \beta}) + \varepsilon_t
\label{eq:ar1}
\end{equation}
where each time step \(Y_t\) is a linear combination of parameters \(\bm \beta\) and a vector of covariates measured at time $t$, \({\bf x'}_t\) plus an autoregressive error term where \(\phi\) is the autoregressive coefficient. We assume the error terms \(\varepsilon_t\) are white noise such that $\varepsilon_1, \varepsilon_2,..., \varepsilon_t \overset{iid}{\sim} \mathcal{N}(0, \sigma^2)$. For our simulations, we used two covariates and simulated 1000 datasets of 365 observations each, representing a year of daily sensor data. 

%times the deviation of the previous time-step from the mean determined by the covariates (i.e. $Y_{t-1} - {\bf x}_{t-1}'{\bm \beta}$). The error term \(\varepsilon_t\) captures both error in this model representation of the variable as well as measurement error, and we assume that $\varepsilon_1, \varepsilon_2,..., \varepsilon_t \overset{iid}{\sim} \mathcal{N}(0, \sigma^2)$ are white noise error terms. 

We fit the above AR(1) error model to an empirical dataset of daily river gross primary productivity (GPP) across three years in the Au Sable river in Michigan, USA  \citep{hall_turbidity_2015}. This dataset includes daily GPP (g \(O_2\) \(m^{-2}\) \(d^{-1}\)) (which itself was estimated from measurements of dissolved oxygen, water temperature, and light), as  well as daily measurements of light (\(\mu\)mol \(m^{-2}\) \(s^{-1}\)) and discharge (\(m^{3}\) \(s^{-1}\)). While this times series is missing GPP values for 50 days, it still provides 1046 days of data %(we used 699 days for model fitting and 347 days for forecasting). 
In our AR(1) model, we used light and flow as covariates, since they have been identified as primary drivers of GPP \citep{bernhardt_metabolic_2018}. 

\subsection*{Simulated and empirical Poisson population time series model}

Time series with integer-valued error distributions (which we subsequently refer to as "time series of counts"), such as annual counts of population size, are also very common in ecology. Approaches for dealing with missing data in these types of time series are not as well developed as they are for data with continuous values that can often be modeled assuming Gaussian errors. For these reasons, we evaluated the impact of missing data on estimator performance using both simulated and empirical data that represent annual counts of individuals in a population. 


We simulated time series data of annual counts of individuals in a population using a stochastic Ricker population model \citep{ricker1954stock} such that:

\begin{subequations}
\begin{align} \label{eq:ricker2}
    \eta_{t+1} &= N_t e^{(r - \alpha N_t)}\\
    N_{t+1} &\sim f(\eta_{t+1})
\end{align}
\end{subequations}

\noindent where \(\eta_{t+1}\) represents the expected population size at time \(t+1\), \(r\) is the intrinsic, density-independent growth rate of the population, and $\alpha > 0$ is the intraspecific competitive effect that induces negative density dependence. %The population carrying capacity is determined as $K= r/\alpha$. 
Realized population size, $N_{t+1}$, is a random draw from the distribution $f()$ with mean $\eta_{t+1}$. Throughout our simulations, we set $f()$ to be a Poisson distribution with rate parameter $\eta_{t+1}$%, though other error distributions may be appropriate in different empirical applications
. We simulated 1000 datasets of 60 observations each, representing 60 years of annual census data. 

Paralleling our above approach, we fit the above Ricker model to a 59-year sequence of annual counts of great tit (\textit{Parus major}) broods in the Wytham Woods in Oxford, UK (Ben Sheldon, personal communication, https://wythamtits.com). These census data are continuous from 1960 - 2018 with no missing values. %(we used 48 years for model fitting and 10 years for forecasting).  

\subsection*{Introducing Missingness into Time Series}

To assess the ability of different missing data approaches to account for differing amounts and types of missing data, we created "missing datasets" by systematically removing observations from both the empirical and simulated time series (Fig.\ \ref{fig:missingtypes}). First, we created datasets with observations of the response variable ``missing completely at random" (MCAR). Additionally, the missingness pattern in MCAR data could have high or low autocorrelation such that missing values were temporally clumped or evenly distributed across the time series. We also created datasets with data ``missing not at random" (MNAR), by removing observations whose numerical value was in the lower or upper tail of the distribution of the response variable. MCAR data might arise due to an individual data logger stopping due to an electronic issue or skipped census dates due to researcher illness, whereas MNAR data might arise due to a flow meter being swept away at high river flows or a temperature logger systematically failing to record observations when the temperature is too low. These scenarios are meant to represent potential processes that would commonly occur in ecological data collection, but are not intended to be exhaustive.

We created MCAR datasets with varying proportions of missing data and degrees of autocorrelation in missingness (Fig.\ S1 B--E) by viewing a time series as a Markov-modulated Bernoulli process where the variable could have two states: missing or not missing \citep{Gharib2014, Edwards1960}. We used a transition matrix to stochastically introduce increasing levels of missingness into both empirically-estimated and simulated GPP and population count time series (see \textbf{Supplemental information: Introducing Missingness} for more information). For each unique simulated time series, we created 150 MCAR missing datasets: one for each possible combination of missingness ranging from 5 to 75\% by increments of 5\% and autocorrelation ranging from 0 to 0.9 by increments of 0.1. We also created 450 MCAR missing datasets using each of the empirical GPP and population count time series, each with a unique combination of missingness and autocorrelation. To more easily examine forecast accuracy across multiple axes of variation, we restricted the possible values of missingness to 20$\pm$5\%, 40$\pm$5\% and 60$\pm$5\% and the possible values of autocorrelation to 25$\pm$5\%, 50$\pm$5\% and 75$\pm$5\%.


We created Gaussian datasets with data missing not at random (MNAR) by removing observations at both the high and low tails of the distribution of data (Fig.\ S1 F,G). These types of MNAR scenarios, where the value of the variable itself is related to its probability of missingness, often occur in sensor data similar to our GPP example. %However, the MNAR pattern of missingness is unlikely to occur in the population count data with Poisson error because the size of a population in a given year is unlikely to affect the probability of missing data collection that year. (It is important to note that while very low population size may lead to false zeros in a time series of count data, observation error is a problem distinct from missing data). Because of this difference, we did not create MNAR missing datasets for simulated or real data with Poisson error. 
For each of the simulated AR(1) process time series we created 15 MNAR missing datasets with missingness increasing from 5 to 75\% by increments of 5\%. We also created 15 MNAR missing datasets using each the empirical GPP time series, but in order to more easily examine forecast accuracy across multiple axes of variation, we restricted the possible values of missingness to 20$\pm$5\%, 40$\pm$5\% and 60$\pm$5\% (For more detail, see Supplemental \textbf{Information: Introducing Missingness}). We did not create Poisson datasets with MNAR missingness because that has no real-world parallel: in population count data, the size of a population is unlikely to affect the probability of missing data collection that year (It is important to note that while very low population size may lead to false zeros in a time series of count data, observation error is a problem that is related but distinct from missing data). In total, we generated 450 MCAR missing datasests with real Gaussian data, 15 MNAR missing datasets with real Gaussian data, 15,000 MNAR missing datasets with simulated Gaussian data, 150,000 MCAR missing datasets with simulated Gaussian data, 450 MCAR missing datasets with real Poisson data, and 150,000 MCAR missing datasets with simulated Poisson data. 


\subsection*{Comparing missing data approaches}

We evaluated several, previously-published approaches for accounting for missing data: simple and complete data deletion, multiple imputation (MI), the Kalman filter, the expectation maximization (EM) algorithm, and Bayesian data augmentation (DA) (Fig.\ \ref{fig:ConceptualFigure}; see below for more detailed descriptions). We used four of the approaches for both real-valued time series and time series of counts, but only used the Kalman filter for real-valued data, and only used EM for time series of counts. %We fit either an AR(1) (for Guassian data) or Ricker (for Poisson data) statistical model to each of the simulated and empirical time series. 
In the cases of both types of data deletion and multiple imputation, we applied the missing data approach \textit{before} fitting the corresponding statistical model. For the simulated and empirical population count time series, we fit a Poisson generalized linear model (GLM) with the \texttt{glm} function from the \texttt{stats} package in R \citep{r_2021}. For the simulated and empirical real-valued data, we fit an AR(1) model with two covariates using the \texttt{arima} function from the \texttt{stats} package in R \citep{r_2021}. For the Kalman filter, EM, and DA approaches, the missing data were addressed simultaneously with the model fitting process (Fig. \ref{fig:ConceptualFigure}). 

\noindent\textbf{Impact of missing data and missing data approach on parameter recovery:} We used models fit to \textit{simulated} time series to determine how the missing data approach, data type (i.e. real-valued or count data), and the type and amount of missingness affected our ability to recover the model parameters used to simulate the data. For both types of simulated time series, we applied a missing data approach and fit a statistical model to the full extent of the time series. We then compared the parameter estimates to the parameters used in each simulation. The parameters we evaluated were $\phi$ and the $\beta$ coefficients for each covariate from the AR(1) models (Eq. \ref{eq:ar1}), and $\alpha$ and $r$ for the Ricker models (Eq. \ref{eq:ricker2}).

We then compared measures of bias and precision of parameter estimates across approaches for a given data type, missingness type (MNAR or MCAR with low, medium, or high autocorrelation), and amount of missing data. First, we calculated relative error,$e_s = \frac{\hat{\theta}_s - \theta_s}{\theta_s}$, and absolute relative error, $|e_s| = \frac{\hat{\theta}_s - \theta_s}{|\theta_s|}$ for each parameter in each model, where $e_s$ is the relative error of $\hat \theta_s$, which estimates the true parameter $\theta_s$ for simulation $s$. These relativized values allowed us to compare parameter recovery across datasets with different simulation parameters as well as compare different parameters within a given model (e.g, regression coefficients to auto-regressive coefficients). A relative error of 0 indicates perfect parameter recovery for that simulation, while a positive or negative error indicates an over or under estimate of a parameter, respectively. Then, we grouped models first by data type, then by the missing data approach used (data deletion, MI, etc.), the type of missingness in the time series used to fit the model (MCAR or MNAR), and proportion of missingness (rounded to the nearest 10\%). Finally, we categorized MCAR datasets as ``low autocorrelation" ($25 \pm 5\%$), ``moderate autocorrelation" ($50 \pm 5\%$), and ``high autocorrelation" ($75 \pm 5\%$).

Within each of these `bins', we calculated the median of the relative error (which we call "Median error"), median absolute relative error ("Median absolute error"), and interval coverage for each model parameter ("Coverage"). We used the median of the relative error distribution as an estimate of bias due to heavy tails in the error distribution and finite simulation numbers. A positive or negative median error indicates systematic over- or under-estimation of that parameter. The median absolute error gives an idea of the variance of the estimator. A high median absolute relative error indicates that an approach leads to unstable estimates across models fit to many simulated datasets. Coverage indicates the proportion of times when the 95\% confidence interval estimated from a fitted model contains the true parameter. Coverage closer to 0.95 indicates that an approach comes with an appropriate measure of uncertainty. We note that, since we relativized the estimates and because the two $\beta$ parameters in the AR(1) model are of the same class (i.e. regression coefficients), we pooled their results. We ultimately used these metrics of the central tendency (median relative error) and spread (median absolute relative error) of the error distribution, as well as coverage to understand how the missing data approach and the amount and type of missingness impacted parameter recovery in models fit to simulated time series.

\noindent\textbf{Impact of missing data and missing data approach on forecast accuracy:} 
We used models fit to empirical time series to determine the impact of missing data approach, data type, and the type and amount of missingness on a model's ability to forecast held-out data. For both types of empirical time series we fit statistical models to a portion of the times series, and then used the resulting model to forecast the remaining time steps. In the Au Sable GPP time series, models were fit to the first two years of daily GPP data (~66\% of the total time series), and then the resulting model parameters were used to forecast the remaining year of daily GPP (~33\%) (Fig. \ref{fig:ParamRec_Gauss} A). In the great tit population size time series, we used the first 49 years of brood size counts (83\%) to fit models, then used the resulting model parameters to forecast the last 10 years of data (17\%).

We then compared model forecasts to the observed values for the forecasted part of each time series, and calculated the root mean square error (RMSE) of each forecast. As described above, we binned these RMSE values according to the dataset characteristics (GPP or population data, MAR or MNAR missingness, missingness, and autocorrelation), and then by the missing data approach used. This RMSE value indicated the accuracy with which a model was able to forecast future time steps, with higher RMSE values indicating lower precision and accuracy and lower RMSE values indicating higher precision and accuracy.     


\subsection*{Missing Data Approaches}

\noindent\textbf{Simple and Complete Data deletion:} 
% State what we did [what pkg did we use for the data deletion? We used nothing special, at least for the Ricker sims we simply did the deletion using standard methods and then used glm from base R stats to fit the model] 
We considered two different data deletion methods in our analyses. The ``simple data deletion" approach involves removing missing values from a time series, compressing the dataset, and running the model as if the time intervals between observations were all equal (Fig. \ref{fig:ConceptualFigure} A). This method violates the assumption of equal temporal spacing between observations -- an assumption implicit in most time series models -- but we include it here as a reference because it is simple and commonly used in published studies. We also include ``complete case data deletion," which is a slightly more rigorous approach than simple data deletion but is still easy to implement. This approach maintains equal spacing between observations by removing a missing value itself as well as the subsequent observation(s) that is predicted by the missing value (Fig. \ref{fig:ConceptualFigure} A). However, those observations after a missing value are retained as predictors of the subsequent observation(s). 


\noindent\textbf{Multiple imputation: }Multiple imputation (MI) is an approach for addressing problems of missing data that systematically fills in missing observations with imputed values, and creates several different versions of complete data sets that can be used to estimate uncertainty around each imputed value (Fig. \ref{fig:ConceptualFigure} B). MI is commonly used in ecology, with multiple studies evaluating methods and approaches to conduct MI for functional traits \citep{taugourdeau_filling_2014,johnson_handling_2021,penone_imputation_2014}, population biology \citep{onkelinx_working_2017}, time series \citep{hui_gap-filling_2004}, and meta-analyses \citep{ellington_using_2015}.  See \textbf{Supplemental Information: Missing Data Approaches}, for more information about how we implemented MI with population count data.  Following execution of multiple imputation using Amelia II, we fit statistical models to time series following the methods described in \textbf{Comparing missing data approaches}. 


\noindent\textbf{Kalman Filter:} The Kalman Filter was developed to estimate the state of a dynamic system that is observed with error but can be used to derive the likelihood function of a time series with missing observations (Fig. \ref{fig:ConceptualFigure} C). The Kalman Filter is primarily focused on estimating the unobserved state of the system, $X_t$, and can be conceptualized as a two-step procedure in which, given an initial state $X_0$, we can forecast the next state $X_1$. Then, following data collection at the next time point, $y_1$, we update the forecast using Bayes' theorem. 
See \textbf{Supplemental Information: Missing Data Approaches} for more information about how we implemented the Kalman Filter.

The Kalman filter assumes a Gaussian error distribution, so we only used this method with the simulated and empirical Gaussian time series. We implemented the Kalman filter missing data approach at the same time as the model fitting process, where we fit an AR(1) model with two covariates using the \texttt{arima} function from the \texttt{stats} package in R \citep{r_2021} (the Kalman filter is the default algorithm used to handle missing values in this R function). 


\noindent\textbf{Expectation maximization algorithm: }The expectation maximization (EM) algorithm is an iterative algorithm that is conceptually similar to the Kalman Filter, and recursively computes the likelihood of a time series with missing data (Fig. \ref{fig:ConceptualFigure} D). See \textbf{Supplemental Information: Missing Data Approaches} for more information about how we implemented EM.

Given its similarity to the Kalman filter, we only used this missing data approach for the simulated and empirical count time series. We constructed an approximate EM algorithm to estimate the parameters of the Ricker model in which missing data were rounded to the nearest integer value during the expectation step such that the likelihood was well-defined for the filled-in series. As such, the missing data were dealt with at the same time as the model fitting process. We used the \texttt{optim} function from the \texttt{stats} package in \texttt{R} for the maximization step \citep{r_2021}. In Figure S2%\ref{fig:EM-bias-checks}
, we show that the estimates are asymptotically unbiased. Note that the algorithms required to estimate standard error of parameter estimates generated from EM are notoriously unstable and difficult to implement in R, so the results of models we fit using this missing data approach do not include standard error estimates. 


\noindent \textbf{Data augmentation}: Data augmentation (DA) provides a model-based framework for estimating missing observations as well as the parameters of interest, but comes with the added benefit of standard errors for the estimates of all the unknown quantities by treating the missing observations as additional parameters to be estimated (Fig. \ref{fig:ConceptualFigure} D). See \textbf{Supplemental Information: Missing Data Approaches} for more information about how we implemented DA.

%Figure \ref{fig:bias-checks} shows that this algorithm also converges on the ``true" parameter values with increasing sample sizes. 



%\begin{enumerate}
 %   \item Comparing the performance of model approaches for simulated data 
%\begin{enumerate}
 %   \item compare the accuracy of parameter recovery for different methods -- are estimates biased? 
 %   \item compare the precision of different approaches (i.e. average SD for each parameter estimate or 95\% CI across all simulations for each parameter estimate) 
  %  * Q: do we want to do this for all parameters? For just a couple?-- maybe combine fixed effects of light and discharge somehow? 
   % * potentially include the rate at which models fail? (i.e. how sharply does the rate of model non-convergence increase as the amount of missingness increases?)
%\end{enumerate}
%\item Comparing the performance of model approaches for real data 
%\begin{enumerate}
%    \item compare of methods in terms of estimation error (compare forecast RMSE)
%\end{enumerate}
%\end{enumerate}

%* Explain how we did this uniquely for Gaussian and Poisson error, for models using MNAR data with increasing amounts of missingness and then for models using MAR data with both increasing levels of missingness and autocorrelation

\section*{Results}

\subsection*{Parameter recovery in models of real-valued time series}

For the real-valued, simulated data with MCAR missingness in the response, all approaches had similarly accurate and precise $\beta$ parameter estimates across all levels of missing data, with median error and median absolute error below 10\% and confidence interval coverage very near 95\%. In contrast, estimates of the autoregressive parameter, $\phi$, were more affected by missing data, and some missing data approaches performed better than others (Fig. \ref{fig:ParamRec_Gauss}). Notably, the data augmentation and Kalman filter methods had the strongest overall performance, with low error and accurate coverage of $\phi$ with as much as 60\% missing data. All other approaches lost both accuracy and CI coverage as the amount of missing data increased. The two data deletion methods, simple and complete-case, had essentially the same ability to recover $\phi$. Both of these methods had increasing median error and absolute median error as the amount of missingness increased, while coverage dropped as low as $\sim70\%$ (see Fig. \ref{fig:ParamRec_Gauss}). Multiple imputation had the worst performance of all five approaches we applied to the real-valued data across every level of missingness. Coverage dropped sharply when more than 10\% of the data were missing, while median error became more negative (indicating a stronger bias toward zero) and median absolute error steadily increased with any amount of missing data. In some cases, multiple imputation underestimated the parameter by over 50\%. The combination of large magnitude errors and low CI coverage seen in the lowest-performing approaches demonstrates that they could be especially misleading. 

Unsurprisingly, misleading parameter estimates were an even greater concern when fitting models to data with observations that were MNAR.  Whereas inaccurate estimates with misleading confidence intervals were only an issue when estimating autoregressive coefficients ($phi$) when observations were MCAR, our analysis indicates that these misleading estimates occur for both $\beta$ and $\phi$ parameters with every missing data approach, and at every level of missingness when data are MNAR (Fig. \ref{fig:ParamRec_Gauss}). All missing data approaches tended to underestimate $\phi$ by up to 95\%, and overestimate $\beta$ by up to $\sim40\%$.  CI coverage for $\beta$ plummeted from $\sim75\%$ with low missing data, to below 50\% when 10\% of the data were missing, and ended close to 0\% coverage with 40\% or more of the data missing (see Fig. \ref{fig:ParamRec_Gauss}). 


The degree of autocorrelation in missing data also affected parameter recovery, but only for data deletion methods and only for $\phi$ (see Fig. SX for the effect of autocorrelation on $\beta$ estimates). Specifically, higher levels of autocorrelation led to more accurate estimates of $\phi$ when either complete case or simple data deletion were used, while other approaches were consistently accurate (Fig. \ref{fig:heatMap_gauss_MAR}). This is most likely because higher levels of autocorrelation in missingness preserved longer segments of intact data, which are important for estimating autoregressive parameters such as $\phi$. However, it is important to note that our simulations assumed no change in parameter values through time (i.e. generated stationary time series), so long stretches of intact data are equally valuable in the model fitting process regardless of when they occur in the time series. If this assumption were violated, high autocorrelation in missingness might not have the same beneficial effect on parameter estimates.   

\subsection*{Parameter recovery in models of count time series}
When fitting Ricker models to simulated time series of count data with observations that were MCAR, the simple data deletion approach did not recover r or $\alpha$ model parameters as accurately as other approaches, particularly as amounts of missing data increased (Fig. \ref{fig:ParamRec_Pois}). Among the remaining approaches, EM consistently had low median error and absolute median error. Interestingly, complete-case data-deletion also had low median error, similar to expectation maximization, but higher median absolute error than EM; however, this pattern was reversed for DA, which recovered parameters with relatively higher median error than EM, but lower median absolute error (i.e. the estimates were more stable, but slightly more biased). Finally, MI recovered parameters with higher values of both median error and median absolute error, though was still much more accurate and precise when compared to simple data deletion. %These trends were very similar for estimates of both $r$ and $\alpha$, reflecting the fact that estimates of growth and competition parameters are correlated in Ricker-type models \citep{bender1984perturbation}. 
Similar to the results for real-valued time series, autocorrelation in missing data lead to more accurate parameter estimates for the simple data deletion method, but had little impact on other methods (Fig. SX).

When considering the coverage of parameter estimates from each method, several important patterns arise. First, simple data deletion had the lowest coverage among all methods (Fig. \ref{fig:ParamRec_Pois}). Taken together with its poor performance in terms of error, this suggests that methods relying on simple data deletion will be particularly dangerous as parameter estimates are likely to be quite inaccurate but accompanied by overly narrow confidence intervals. Just as in the simulations of real-valued data, this same problem applies to MI, though to a lesser extent than for simple data deletion. On the other hand, DA and complete-case data deletion both maintain close to 95\% coverage across a range of missing data amounts, suggesting these methods are accurately quantifying uncertainty around parameter estimates. Importantly, EM does not provide standard error for parameter estimates so coverage for this method cannot be assessed. Researchers should therefore only consider EM if they do not need to account for uncertainty in parameter estimates.


\subsection*{Forecasting and missing data}
When real-valued data are MCAR, increasing the proportion of missing data resulted in higher median and variance of the forecast Root Mean Squared Error (RMSE) across multiple model runs (Fig. \ref{fig:RMSE_Gaus} B). This effect was strongest for the variance of RMSE. Thus, while it is possible to generate relatively accurate predictions with high levels of missing data, the likelihood of accurate predictions from any given model fit to high missingness data is largely dependent on which individual data points are missing. Second, all missing data approaches performed similarly in terms of forecast RMSE. This might reflect the relative importance of the environmental parameters in the model as the estimates of the regression coefficients were much less impacted by missing data compared to the autocorrelation parameter $\phi$ (Fig. \ref{fig:ParamRec_Gauss}). Finally, when data were missing not at random (MNAR), model forecasts had substantially increased RMSE as the amount of missingness increased. In fact, only 20\% of data MNAR led to worse forecasts across methods than when 60\% of the data were MCAR. Variance of RMSE did not meaningfully change as the amount of data MNAR increased. 

As with the real-valued time series, the count data with observations that were MCAR also saw both the median and variance of forecast RMSE increase as the amount of missing data increased (Fig. \ref{fig:RMSE_Poiss}). This pattern was consistent across all of the missing data approaches. In particular, the variance of forecast RMSE increased substantially as missingness increased, underscoring that \textit{which} individual data points are missing can strongly affect the accuracy of model fit and predictions. While most methods performed similarly in these forecasts, MI had generally lower median RMSE, particularly at higher amounts of missing data. It should be noted, though, that RMSE is relatively high across all methods and amounts of missing data. 

\section*{Discussion}

 Missing data are a nearly ubiquitous issue in ecological studies and can be particularly problematic when fitting autoregressive time series models, since missing values violate a key statistical assumption that observations are equally spaced in time. We evaluated six previously proposed approaches for dealing with missing data by fitting autoregressive models to simulated and empirical examples of two different types of time series common in ecology: daily observations of a continuous variable with a Gaussian error distribution (analogous to sensor data) and annual observations of a discrete variable with a Poisson error distribution (analogous to count data, such as trends in population size). 
 
Our results indicate that parameter estimation can be fairly robust to missing data if data are MCAR or MAR and analyzed an appropriate model for the likelihood of missingness and the error distribution of the time series (e..g Gaussian vs. Poisson). Thus, missing values in time series do not necessarily have a catastrophic effect on model accuracy, precision, or forecast ability. In fact, several methods, such as DA and the Kalman filter when applied to real-valued time series data and EM when applied to time series of counts could recover simulation parameters with relatively high accuracy and precision, even when 50\% of observations were missing completely at random (although we do not suggest fitting models to time series with this much missing data). Similarly good performance was found using MI for high missingness in non-time series data \citep{graham_missing_2009}. 

While we found several missing data approaches that performed well for a range of data and missingness types, we also identified some approaches that were uniformly unsuitable. Simple data deletion, where missing observations are deleted from the time series and the unequal spacing between observations is ignored, led to inaccurate and imprecise models despite being one of the commonly used methods in ecological analyses. Multiple imputation was also quite inaccurate and imprecise, especially for fitting AR(1) models to real-valued times series data. Additionally, we found that when data are missing not at random (MNAR), none of the methods we considered here provided robust parameter estimates. Handling missingness that is not missing \textit{completely} at random requires knowing the missingness mechanism such that the likelihood of missingness can itself be modeled. This may be a tall order in many ecological systems  \citep[e.g.,][]{Sotto2011_mnar, McCall2014_mnar, Shoari2018_mnar} %Below, we further explore the impacts of the different amounts and types of missing data we considered on model performance, and provide more specific recommendations for missing data approaches given certain types of data and missingness.

Identifying the mechanism of missingness in the data, i.e. the structure behind the missing data values, informs selection of the best missing data approach. If the values are MCAR in a time series, our results suggest that within each data type, each of the missing data approaches we evaluated tended to perform consistently well or poorly in terms of parameter recovery (Fig. \ref{fig:ParamRec_Gauss}, Fig. \ref{fig:ParamRec_Pois}). The best-suited approach will depend on research goals and characteristics of the time series itself. Conversely, the missing data approaches we assessed provide universally poor parameter recovery and forecast accuracy for time series with MNAR data. We therefore do not recommend any of the missing data approaches we evaluated when missing values are MNAR. Many ecological time series may contain data that are MNAR \citep{bowler2025treating}, but this may be difficult or even impossible to verify (\citep{nakagawa_missing_2015}). If the variables or processes behind MNAR missingness can be identified, observed, and controlled for in the modeling process, the missing data can be treated as MCAR, which then makes common missing data approaches more viable \citep{newman_missing_2014, nakagawa_missing_2015}. Therefore, it is important for researchers to carefully consider their study system, identify drivers that could potentially lead directly or indirectly to data that are MNAR, and ensure they measure these drivers. Recording reasons for missing observations when they occur can help identify the mechanism driving missingness in a system. In short, MNAR data can have dire consequences for precision and accuracy, but thoughtful investigation and planning prior to time series collection can mitigate the negative impacts.  

While our analyses indicate that the most suitable missing data approach will depend on many factors, we can make some general recommendations. First, choice of missing data approach should be informed by the goal of an analysis, and what information is necessary for further analytical steps. For example, if you require numerical estimates of missing values, then out of the approaches we evaluated, only multiple imputation and data augmentation would suit your needs. An additional general recommendation is that, regardless of the data type, amount and type of missingness, or analysis goal, simple data deletion should be used only with the utmost caution--advice that has been emphasized previously \citep[e.g.,][]{nakagawa_model_2011, Shoari2018_mnar,lopucki2022handling}. Simple data deletion has the tendency to substantially over or underestimate parameter estimates and underestimate confidence intervals of those parameters. This effect was considerable in the case of models we fit to simulated count data (Fig.\ \ref{fig:ParamRec_Pois}), but was less extreme in parameters from models fit to real-valued data simulated with an AR(1) model (Fig.\ \ref{fig:ParamRec_Gauss}). We expect the adverse effects of simple data deletion may have been mitigated by including two covariates that did not have missing values in our simulations, while the Ricker model we used to simulate time series of counts did not have covariates. %Interestingly, simple data deletion led to the widest range of forecast RMSE when forecasting the great tit empirical dataset with 60\% missing data (Fig.\ \ref{fig:RMSE_Poiss}B), suggesting that the predictive performance of this approach is inherently tied to the composition of the missing data. This complexity was also found in the empirical Gaussian forecasting, where simple data deletion was the best for missing not at random and among the worst for missing at random treatments (Fig.\ \ref{fig:RMSE_Gaus}B). Inconsistency in predictive performance across datasets is troubling, and makes the use of simple data deletion even more questionable. 
While it may be intuitive that simply removing data points creates irregular time-steps and violates model assumptions, simple data deletion is straightforward to implement and can actually occur under the hood in some modeling packages without being obvious to the user. For example, many R functions include arguments for automatically removing NA values (e.g. na.exclude, na.omit, na.rm, etc.), which are easy to utilize without an adequate understanding of their implications. Fortunately, there are several other missing data approaches we examined here that are straightforward to implement, are more robust than simple data deletion, and don't violate underlying assumptions of time series models.

%(Could this also serve as a call to develop methods streamlining other ways to deal with missingness?). 
%For example, the \texttt{arima()} function from package \texttt{stats} requires the presence of \texttt{NA} values in place of the missing data (rather than dropping \texttt{NA}'s from the data) in order to properly account for unequal spacing among observed values. 


For real-valued time series with missingness completely at random (MCAR), every missing data approach we evaluated was able to recover the parameters for $\beta$ covariates with consistently appropriate coverage and low error (Fig. \ref{fig:ParamRec_Gauss}). If you have real-valued data and care more about the covariate relationships ($\beta$s) than autoregressive ($\phi$) parameters, any of the missing data approaches could work for you (aside from simple data deletion). If you also prioritize accurate and precise autoregressive parameter ($\phi$) estimation, your options are more limited if you have more than ~10\% of observations MCAR. Only two approaches had similarly strong recovery of $\phi$: the Kalman filter and data augmentation. These methods also remained effective at every level of autocorrelation in missingness (Fig. \ref{fig:heatMap_gauss_MAR}). In contrast, both of the data deletion methods (simple and complete case) had consistently poor performance for $\phi$ recovery, although their median error at a given level of missingness was reduced when autocorrelation in missingness was higher. While simple data deletion should always be avoided, complete case data deletion may be a decent and simple option, at least for models with low-order autoregression (e.g. AR(1) or AR(2)). Multiple imputation was not the worst method but it was far from the best, so we would not recommend it for autoregressive parameter estimation, despite being a commonly recommended method for ecologists \citep{nakagawa_missing_2008,ellington_using_2015}.  When forecasting with the real GPP data from the Au Sable river with observations MCAR, all approaches performed well. RMSE did not substantially increase as the amount of missing data increased (Fig. \ref{fig:RMSE_Gaus} B). We believe this is largely because the environmental covariates are much more important for forecasting the mean response than the autoregressive parameter. Thus, because all approaches had strong covariate parameter recovery, they were all able to forecast well.

 We found that several missing data approaches performed differently when we applied them to time series of counts with observations that were MCAR. Parameter recovery was more uniform across all of the approaches than with real-valued data, but complete case data deletion, EM, and DA were the most accurate and precise for parameter recovery (Fig \ref{fig:ParamRec_Pois}). %Also, with the Poisson data, increasing autocorrelation was only a factor for simple data deletion rather than both simple and complete case data deletion as occurred with the Gaussian data (Fig S_). 
We hypothesize that the difference in the performance of missing data approaches between real-valued and count time series were due to the difference in the autoregressive component of the model structure between the Ricker model and AR(1) model.%: The Ricker model only uses abundance at the previous time step,  $t – 1$, to predict abundances at time $t$. In contrast, the AR(1) uses both the value of the response at $t-1$ as well as two covariates to predict a value at time $t$. The relatively simple structure of the Ricker model we used may explain why complete case data deletion performed well with Poisson data but poorly with Gaussian data. %, and was not affected by autocorrelation in missingness.
Forecasts using models fit to the great tit census time series with observations MCAR had quite variable RMSE across all missing data approaches (Fig. \ref{fig:RMSE_Poiss}. This could be because the Ricker model we used did not include covariates, so any amount of missing data had the potential to substantially alter model fit and thus forecast accuracy. However, previous analyses of the great tit dataset we used suggest that such simplistic models, even if they incorporate environmental drivers, may be inadequate to describe fluctuations in this dataset, and that more complex functional relationships or spatial processes may be necessary \citep{lebreton1990modelling}. Regardless of the overall highly variable RMSE, median forecast error increased markedly as the amount of missing data increased for all missing data approaches, especially when compared to the relative amount that RMSE increased in forecasts for the Au Sable river GPP dataset (Fig. \ref{fig:RMSE_Gaus} B). This indicates that missing data may be particularly damaging to forecasts that use autoregressive models with no covariates. 
         
% P5 -  Topher's "caveats" paragraph? Contains info from 3/12 minutes as well as info added ... a while ago. - CT
Our results provide important insights into the performance of a variety of methods for dealing with missing data in ecological time series; however, we note that our simulations should perhaps best be viewed as benchmarks demonstrating best and worst case scenarios. For example, we did not explore all the nuances of each available method for the sake of a clear and concise comparison, but several of the methods could be `tuned' to achieve better of worse performance (e.g., MI might perform better if using more imputed datasets \citep{honaker_what_2010} while the Kalman Filter might perform worse when setting the Kalman gain below one to account for observation error \citep{kalman_filter_1960}). Further, we chose to only explore the effect of missing data in the response variable, and assumed no missingness in the covariates. However, ecological datasets often have missing data in the covariates as well as the response, which would complicate the modeling approach. There is much literature on the problem of missing data in covariates (albeit, not necessarily in the context of time series) that is beyond the scope of this manuscript \citep{Little_1992}.
Similarly, we chose an empirical dataset of stream GPP with known, strong effects from environmental covariates \citep{hall_turbidity_2015,bernhardt_metabolic_2018}. %meaning the accurate estimates of $beta$ parameters likely played a large role in achieving accurate forecasts even in scenarios where the autoregressive parameter estimates were estimated poorly. 
In more exploratory scenarios or systems with weaker covariate effects, inaccurate estimates of autoregressive parameters might have larger, negative effects on model forecasting ability. Finally, we only explored scenarios with data Missing Completely At Random and data Missing Not at Random (MCAR and MNAR), representing opposite ends of a spectrum from best to worst case scenarios \citep{newman_missing_2014}. While we did not explore scenarios with data Missing At Random (i.e., with the probability of missingness dependent on one or more covariates; \citep{newman_missing_2014}), we argue model performance in this case would fall in between our two MCAR and MNAR scenarios. %Since MAR data would be more likely to be missing for certain values of environmental covariates, the parameter estimates associated with those covariates would likely suffer \citep{nakagawa_missing_2008} with cascading effects for the model's predictive accuracy. How closely the results for such a MAR scenario would fall to the two scenarios we present would depend on the strength of the relationship between covariate values and the probability of missingness and which values of the covariate were most likely to cause missingness. For example, missingness associated with one or both of the extremes of the covariate would be more likely to cause bias in estimates of the associated $\beta$ parameter than missingness associated with average values of the covariate (assuming a linear relationship between the covariate and the response variable). 

Collectively, our comparison of missing data approaches provide a starting guide for dealing with missing data in ecological time series. Our results, especially for the real-valued data to which we fit a regression model with Gaussian AR(1) error, suggest that parameter estimation and forecast accuracy can be robust to relatively high MCAR missingness -- especially if using the "best" method for accounting for missingness -- this is unlikely to hold for all data types or model structures. %This is especially true for shorter time series. 
As a result, we suggest that running similar simulations to those shown here with data that specifically mirror the length, error distribution, and missingness pattern of your own data would be extremely beneficial when deciding how to best deal with missing observations; we argue that this step should become part of the analysis workflow, particularly in a field-based discipline such as ecology where missing observations are often unavoidable. %For ecologists wanting to apply these date missingness data approaches, we suggest simulating data according to the model(s) they will use and missingness type of their data, to compare methods and better understand systematic bias and uncertainty when working with data with missing values. 



%\end{linenumbers}

\newpage


\section*{Figures}

%% Figure 1

\begin{figure}[!htb]
     \noindent\includegraphics[width = 0.85\textwidth]{Figures/CompareMissingnessTypes_fig.png}
     \caption{An example time series demonstrating different types and amounts of missing data. The left column shows the same time series with different amounts and types of missingness and right column shows the distribution of data points in each resultant time series. A. Complete time series with no missing data. Rows B through E show the time series with 10\% (B and C) or 40\% (D and E) of data missing completely at random (MCAR), with either low autocorrelation in missing data (B and D) or high autocorrelation (C and E). Rows F and G show the time series with data missing not at random (MNAR) for 10\% missing data (F) and 40\% missing data (G).}

     \label{fig:missingtypes}
 \end{figure}



%% Figure 2
\begin{figure}[h]
     \noindent\includegraphics[width = 0.9\textwidth]{Figures/ConceptualFigure.png}
     \caption{Conceptual figure showing different approaches to handling missing data and the mechanisms for each approach}
     \label{fig:ConceptualFigure}
 \end{figure}

%% Figure 3
\begin{figure}
    \noindent\includegraphics[width = .7\textwidth]{Figures/MockedUpFigures/parameterRecoveryGaussian_MARMNARlong.png}
    \caption{Parameter recovery metrics for Gaussian time series: Here we show the median error of parameter recovery, absolute median error of parameter recovery, and 95\% coverage of parameter estimates, resulting from models fit with five missing data approaches across an increasing proportion of missing data. 
    These models were fit to simulated Gaussian datasets with data missing completely at random (MCAR; left panel) with autocorrelation in missingness between $>$0.3 and $<$ 0.6, and data missing not at random (MNAR; right panel). The coverage panel shows the proportion of model runs where the 95\% confidence interval of a parameter estimate includes the true simulation parameter (dotted line at 0.95). Each point in each panel shows the median value of error or coverage across all models fit to simulations that used the same missing data approach, had the same amount of missing data (within a 10\% bin), approximately the same amount of autocorrelation in missingness, and the same type of missingness.} 

    \label{fig:ParamRec_Gauss}
\end{figure}

%% Figure 4
\begin{figure}
    \noindent\includegraphics[width = \textwidth]{Figures/MockedUpFigures/heatmap_GaussianMCAR_justPhi.png}

    \caption{Median error of parameter recovery of $\phi$ depending on the proportion of missing data and autocorrelation in missingness for each of five methods missing data approaches, using simulated Gaussian datasets with data missing completely at random (MCAR). Cells in yellow (closer to 0) show that the median of model estimates of $\phi$  were closer to the actual simulation parameter.}

    \label{fig:heatMap_gauss_MAR}
\end{figure}

%% Figure 5
\begin{figure}
    \centering
    \noindent\includegraphics[width = 0.7\textwidth]{Figures/MockedUpFigures/parameterRecoveryPoisson_MCARlong.png}
    \caption{Parameter recovery metrics for Poisson time series: Here we show the median error of parameter recovery, absolute median error of parameter recovery, and 95\% coverage of parameter estimates, resulting from models fit with five missing data approaches across an increasing proportion of missing data. These models were fit to simulated Poisson datasets where data were missing completely at random (MCAR) with autocorrelation in missingness between $>$0.3 and $<$ 0.6. The coverage panel shows the proportion of model runs where the 95\% confidence interval of a parameter estimate includes the true simulation parameter (dotted line at 0.95). Each point in each panel shows the median value of error or coverage across all models fit to simulations that used the same missing data approach, had the same amount of missing data (within a 10\% bin), approximately the same amount of autocorrelation in missingness, and the same type of missingness.}

    \label{fig:ParamRec_Pois}
\end{figure}

%% Figure 6
\begin{figure}
    \centering
    \noindent\includegraphics[width = 0.85\textwidth]{Figures/MockedUpFigures/RMSE_FullFigure_NoLineWithErrorBar_gaussian_auSable.png}

    \caption{(A) Daily measurements of scaled gross primary productivity (GPP) from the Au Sable River from 2012 through 2015 (699 days). Red tick marks on the x-axis indicate days when measurements were missing. The gray box indicates the data (347 days) excluded from model fitting, which were then forecast using the resulting model. (B) Root mean square error (RMSE) of forecasts made using a model fit to the Au Sable GPP time series shown in panel A. Each point shows the median RMSE across all forecasts with a given missing data approach (indicated by color), in a given level of proportion of missing data (0.2 $\pm$ 0.05, 0.4 $\pm$ 0.05, 0.6 $\pm$ 0.05), and with a given type of missingness (missing completely at random (MCAR) with autocorrelation of 0.5 $\pm$ 0.05 or missing not at random (MNAR)). Error bars indicate the inter-quartile range.}

    \label{fig:RMSE_Gaus}
\end{figure}

%% Figure 7
\begin{figure}
    \noindent\includegraphics[width = \textwidth]{Figures/MockedUpFigures/RMSE_pois_combined.png}
    \caption{(A) Annual counts of Great Tit (\textit{Parus major}) broods in the Wytham Woods from 1960 – 2018. The gray box indicates the data (10 years) that were excluded from model fitting, which were then forecast using the resulting model. (B) Forecast root mean square error (RMSE) of the Great Tit dataset with an increasing proportion of missing data and missingness approaches. Each point shows the mean RMSE across all forecasts with a given missing data approach (indicated by color), in a given level of proportion of missing data (0.2 $\pm$ 0.05, 0.4 $\pm$ 0.05, 0.6 $\pm$ 0.05) with all bars shown for autocorrelation of 0.5 $\pm$ 0.05. Error bars indicate inter-quartile range}
    \label{fig:RMSE_Poiss}
\end{figure}
\clearpage


\newpage

\bibliographystyle{ecology}
\bibliography{citations}

\newpage

%\include{appendix}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\end{document}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
